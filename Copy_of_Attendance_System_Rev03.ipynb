{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trizakiilu/Capstone-2023/blob/main/Copy_of_Attendance_System_Rev03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6ZOaShOecLF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "841b496d-af88-4f2e-82ce-5b4b0aff7a22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting face_recognition\n",
            "  Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.9/dist-packages (from face_recognition) (19.24.1)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.9/dist-packages (from face_recognition) (8.1.3)\n",
            "Collecting face-recognition-models>=0.3.0\n",
            "  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.1/100.1 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.9/dist-packages (from face_recognition) (8.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from face_recognition) (1.22.4)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566185 sha256=4dd4535487810ff06c5eab2dbc03458d666d7ae976be0c0a260fafe5337094c9\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/a8/60/4a2aeb763d63f50190f4c4e07069a22245347eeafdb3a67551\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face_recognition\n",
            "Successfully installed face-recognition-models-0.3.0 face_recognition-1.3.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (8.1.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting schedule\n",
            "  Downloading schedule-1.1.0-py2.py3-none-any.whl (10 kB)\n",
            "Installing collected packages: schedule\n",
            "Successfully installed schedule-1.1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting timeloop\n",
            "  Downloading timeloop-1.0.2.tar.gz (2.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: timeloop\n",
            "  Building wheel for timeloop (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for timeloop: filename=timeloop-1.0.2-py3-none-any.whl size=3717 sha256=be883b5a903d7e9eea5cf5d971b93b31f13b66b55a0e69dfa6d1314a3b3a29f8\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/47/01/8e48745e2b92e8a78dc988d4e9404e4f10ccdcd207dc0cad69\n",
            "Successfully built timeloop\n",
            "Installing collected packages: timeloop\n",
            "Successfully installed timeloop-1.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install face_recognition\n",
        "!pip install click\n",
        "!pip install schedule\n",
        "!pip install timeloop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IoVNTJfse0M7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e63efe8-76df-492c-cc0c-791bf5dbb294"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/' , force_remount=True)\n",
        "import face_recognition\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import os\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os\n",
        "import PIL\n",
        "import io\n",
        "from base64 import b64decode, b64encode\n",
        "import time\n",
        "from datetime import datetime\n",
        "import xlrd\n",
        "import pandas as pd\n",
        "import time\n",
        "from datetime import date\n",
        "import csv\n",
        "today = date.today().strftime('%Y-%m-%d %H:%M:%S')\n",
        "os.chdir('/content/drive/MyDrive/attendance')\n",
        "import Video_Capture\n",
        "capture_number = 0\n",
        "import click\n",
        "import schedule\n",
        "import time\n",
        "import datetime\n",
        "import pytz\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHeIHiG8wacJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ea54ad5-6416-42f7-e07a-429dd74d64e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-03-28 12:32:32.787275-04:00\n"
          ]
        }
      ],
      "source": [
        "# Set the timezone to your desired timezone\n",
        "tz = pytz.timezone('America/New_York')\n",
        "\n",
        "e = datetime.datetime.now(tz)\n",
        "print(e)\n",
        "start_hour = 12\n",
        "strat_minute = 25\n",
        "finish_hour = 12\n",
        "finish_minute = 26\n",
        "time_to_capture = 60  # waiting time for capture next photo (second)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngujvPm2xxXK"
      },
      "outputs": [],
      "source": [
        "def streaming_video(count):\n",
        "    a = Video_Capture\n",
        "    capture_number = 0\n",
        "    video_stream = a.Video_Capture(1).video_stream\n",
        "    video_frame = a.Video_Capture(1).video_frame\n",
        "    js_to_image = a.Video_Capture(1).js_to_image\n",
        "    bbox_to_bytes = a.Video_Capture(1).bbox_to_bytes\n",
        "\n",
        "    video_stream()\n",
        "    face_cascade = cv2.CascadeClassifier(cv2.samples.findFile(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'))\n",
        "    label_html = 'Capturing...'\n",
        "    # initialze bounding box to empty\n",
        "    bbox = ''\n",
        "    \n",
        "\n",
        "    while True:\n",
        "        js_reply = video_frame(label_html, bbox)\n",
        "        if not js_reply:\n",
        "            break\n",
        "        # convert JS response to OpenCV Image\n",
        "        image_bytes = b64decode(js_reply[\"img\"].split(',')[1])         \n",
        "        #img = js_to_image(js_reply[\"img\"])\n",
        "        jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "        # decode numpy array into OpenCV BGR image\n",
        "        img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "        # create transparent overlay for bounding box\n",
        "        bbox_array = np.zeros([600,600,4], dtype=np.uint8)\n",
        "\n",
        "        # grayscale image for face detection\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "        #face_location = face_recognition.face_locations(img)\n",
        "        # get face region coordinates\n",
        "        face_cascade=cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\") \n",
        "        faces = face_cascade.detectMultiScale(gray)\n",
        "        # get face bounding box for overlay\n",
        "        if len(faces) > 0:\n",
        "          for (x,y,w,h) in faces:\n",
        "            bbox_array = cv2.rectangle(bbox_array,(x,y),(x+w+10,y+h+10),(255,0,0),2)\n",
        "          os.chdir('/content/drive/MyDrive/attendance/test/')\n",
        "          filename = f\"{count+1}.png\"\n",
        "          bbox_array[:,:,3] = (bbox_array.max(axis = 2) > 0 ).astype(int) * 255\n",
        "          # convert overlay of bbox into bytes\n",
        "          bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n",
        "          #iobuf = io.BytesIO()\n",
        "          # format bbox into png for return\n",
        "          bbox_PIL.save(filename)\n",
        "          # format return string\n",
        "          #bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n",
        "            # update bbox so next frame gets new overlay\n",
        "          #bbox = bbox_bytes\n",
        "          ### inja ##########################\n",
        "          cv2.imwrite(filename, img)\n",
        "          capture_number += 1\n",
        "          #a.Video_Capture(0).release()\n",
        "          cv2.destroyAllWindows()\n",
        "          \n",
        "          break\n",
        "    return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6bV-m3xY-Wz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b43101de-ef83-4d44-d51f-85002769b969"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The houre is out of rollcall time \n"
          ]
        }
      ],
      "source": [
        "count = 0\n",
        "while True:\n",
        "  if e.hour >= start_hour and e.hour <= finish_hour:\n",
        "    if e.minute >= strat_minute and e.minute <= finish_minute:\n",
        "      print('Its time for rollcall')\n",
        "      streaming_video(count)\n",
        "      print('Face Detected')\n",
        "      time.sleep(time_to_capture)\n",
        "      e = datetime.datetime.now(tz)\n",
        "      count =+ 1\n",
        "    else:\n",
        "      e = datetime.datetime.now(tz)\n",
        "      print(\"The houre is out of rollcall time \")\n",
        "      break\n",
        "  else:\n",
        "    e = datetime.datetime.now(tz)\n",
        "    print(\"The houre is out of rollcall time \")\n",
        "    break\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJ940voJfL4G"
      },
      "outputs": [],
      "source": [
        "def read_train_images(folder , dim):\n",
        "  X = []\n",
        "  encode = []\n",
        "  y = []\n",
        "  Y = []\n",
        "  n_samples=0\n",
        "  none_image = 0\n",
        "  for i in os.listdir(folder):\n",
        "      #print(i) \n",
        "      img_file = cv2.imread( folder +'/' + i)\n",
        "      #cv2_imshow(img_file)\n",
        "      if img_file is not None:\n",
        "          img_orginal=cv2.resize(img_file,dim)\n",
        "          face_location = face_recognition.face_locations(img_orginal)\n",
        "          encoded_img = face_recognition.face_encodings(img_orginal, face_location)\n",
        "          #print(face_location)            \n",
        "          X.append(img_orginal)\n",
        "          encode.append(encoded_img)\n",
        "          name = os.path.split(i)[-1]\n",
        "          Y.append(name)\n",
        "          n_samples+=1    \n",
        "      else:\n",
        "        none_image=+1\n",
        "        print(f'there is {none_image} \"not image\" file in this folder')\n",
        "\n",
        "  return X , Y, encode\n",
        "dim = (600,600)\n",
        "train_folder =  \"/content/drive/MyDrive/attendance/train\"\n",
        "x , y , encoded_images= read_train_images(train_folder, dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVBBX7UCiOyK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4964ee77-ce97-4e79-9297-b12a11287e97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[True]\n",
            "[False]\n",
            "[]\n",
            "No face were detected\n",
            "[False]\n",
            "[]\n",
            "No face were detected\n",
            "[False]\n",
            "[]\n",
            "No face were detected\n",
            "[]\n",
            "No face were detected\n"
          ]
        }
      ],
      "source": [
        "def read_test_image(test_folder, dim, encoded_images, y):\n",
        "  Attendees_list = []\n",
        "  k=0\n",
        "  for iter in os.listdir(test_folder):\n",
        "    test_img = cv2.imread(test_folder + iter)\n",
        "    j = 0\n",
        "    for i in encoded_images:\n",
        "      test_img=cv2.resize(test_img,dim)\n",
        "      face_location_test = face_recognition.face_locations(test_img)\n",
        "      encoded_test = face_recognition.face_encodings(test_img, face_location_test)\n",
        "      #print(len(encoded_test))\n",
        "      if len(encoded_test) == 0:\n",
        "        results = []\n",
        "        \n",
        "      else:\n",
        "        results = face_recognition.compare_faces(np.array(i), np.array(encoded_test))\n",
        "        print(results)\n",
        "        if len(results) == 0:\n",
        "          print('No face were detected')\n",
        "        else:\n",
        "          if results[0]:\n",
        "            Attendees_list.append(y[j])\n",
        "          else:\n",
        "            pass\n",
        "      j+=1\n",
        "    k+=1   \n",
        "  return Attendees_list, k\n",
        "test_folder = \"/content/drive/MyDrive/attendance/test/\"\n",
        "raw_list, K = read_test_image(test_folder, dim, encoded_images, y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5ANeX8x73V1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "943a0606-2b8f-49a7-a454-e95c17092d69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attendees students are :['Amin']\n",
            "Absents students are :['Sherea', 'brad', 'jack', 'Yesha', 'Triza', 'sara', 'John']\n"
          ]
        }
      ],
      "source": [
        "lis_of_attendees = []\n",
        "[lis_of_attendees.append(x) for x in raw_list if x not in lis_of_attendees]\n",
        "\n",
        "absent_list = list(set(y).difference(lis_of_attendees))\n",
        "Absents = []\n",
        "for i in absent_list:\n",
        "  name = i.split('.')[0]\n",
        "  Absents.append(name)\n",
        "\n",
        "Attendees = []\n",
        "for i in lis_of_attendees:\n",
        "  name = i.split('.')[0]\n",
        "  Attendees.append(name)\n",
        "print(f'Attendees students are :{Attendees}')\n",
        "print(f'Absents students are :{Absents}')\n",
        "\n",
        "if K>len(raw_list):\n",
        "  strange_no = K-len(raw_list)\n",
        " # print(f'There are {strange_no} strange person in the class. Be careful!!')\n",
        "  os.chdir('/content/drive/MyDrive/attendance/')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#making report\n",
        "import openpyxl\n",
        "from openpyxl.styles import PatternFill, Font, Alignment,Border,Side\n",
        "from openpyxl import Workbook, load_workbook\n",
        "\n",
        "\n",
        "#make time and date dynamic\n",
        "\n",
        "# Define the data as lists\n",
        "class_name = \"A\"\n",
        "time = \"5:15 to 5:20\"\n",
        "date = \"2023-03-27\"\n",
        "\n",
        "numbers = [1, 2, 3, 4, 5, 6, 7, 8]\n",
        "#names = [\"amin\", \"yesha\", \"triza\", \"sherea\", \"jack\", \"john\", \"sara\", \"soozan\"]\n",
        "student_ids = [605, 608, 604, 606, 609, 602, 603, 601]\n",
        "#statuses = [\"absent\", \"absent\", \"absent\", \"absent\", \"absent\", \"absent\", \"absent\", \"absent\"]\n",
        "descriptions = [\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"]\n",
        "\n",
        "# Combine attendance and absent lists\n",
        "names = lis_of_attendees + absent_list\n",
        "\n",
        " #Create a list of statuses\n",
        "statuses = []\n",
        "for person in names:\n",
        "    if person in lis_of_attendees:\n",
        "        statuses.append(\"present\")\n",
        "    else:\n",
        "        statuses.append(\"absent\")\n",
        "\n",
        "# Open the Excel file\n",
        "#workbook = openpyxl.Workbook()\n",
        "\n",
        "# Select the worksheet you want to modify\n",
        "#worksheet = workbook.active"
      ],
      "metadata": {
        "id": "Ou28kxkngHlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "workbook =  load_workbook(filename=\"classlist.xlsx\")\n",
        "\n",
        "worksheet = workbook.active\n",
        "\n",
        "# Merge cells and make text bold\n",
        "bold_font = Font(bold=True)\n",
        "worksheet.merge_cells('A1:E1')\n",
        "worksheet['A1'].font = bold_font\n",
        "worksheet.merge_cells('A2:E2')\n",
        "worksheet['A2'].font = bold_font\n",
        "\n",
        "# Set border style of bottom edge to None for merged cells A1:E1 and A2:E2\n",
        "for row in worksheet.iter_rows(min_row=1, max_row=2, min_col=1, max_col=5):\n",
        "    for cell in row:\n",
        "        border = Border(bottom=Side(border_style=None))\n",
        "        cell.border = border\n",
        "        \n",
        "# Write the data to specific cells\n",
        "worksheet['A1'] = 'Class ' + class_name\n",
        "worksheet['F1'] = 'time: '\n",
        "worksheet['G1'] =  time\n",
        "worksheet['F2'] = 'date: '\n",
        "worksheet['G2'] =  date\n",
        "\n",
        "worksheet['A3'] = 'number'\n",
        "worksheet['B3'] = 'name'\n",
        "worksheet['C3'] = 'student id'\n",
        "worksheet['D3'] = 'status'\n",
        "worksheet['E3'] = 'description'\n",
        "\n",
        "\n",
        "\n",
        "# Define fill colors for status field\n",
        "present_fill = PatternFill(fill_type='solid', start_color='CEE4CE', end_color='CEE4CE')\n",
        "absent_fill = PatternFill(fill_type='solid', start_color='FACACA', end_color='FACACA')\n",
        "\n",
        "for i in range(len(numbers)):\n",
        "    row = i + 6\n",
        "    worksheet.cell(row=row, column=1, value=numbers[i])\n",
        "    worksheet.cell(row=row, column=2, value=names[i])\n",
        "    worksheet.cell(row=row, column=3, value=student_ids[i])\n",
        "    worksheet.cell(row=row, column=4, value=statuses[i])\n",
        "    worksheet.cell(row=row, column=5, value=descriptions[i])\n",
        "    \n",
        "    # Set the fill color based on the value of the \"status\" field\n",
        "    if statuses[i] == 'present':\n",
        "        worksheet.cell(row=row, column=4).fill = present_fill\n",
        "    else:\n",
        "        worksheet.cell(row=row, column=4).fill = absent_fill\n",
        "\n",
        "# Save the changes to the Excel file\n",
        "workbook.save('classlist.xlsx')"
      ],
      "metadata": {
        "id": "1JYP626ZgZrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mailing report to teacher\n",
        "import os\n",
        "import smtplib\n",
        "from email.mime.multipart import MIMEMultipart\n",
        "from email.mime.base import MIMEBase\n",
        "from email.mime.text import MIMEText\n",
        "from email.utils import COMMASPACE\n",
        "from email import encoders\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "\n",
        "# Set email parameters\n",
        "sender = 'durhamattendance@gmail.com'\n",
        "password = 'ytsfrxfvssiaucms'\n",
        "recipient = 'aminysf23@gmail.com'\n",
        "subject = 'Test Email with Excel attachment'\n",
        "body = 'Please find attached the Excel file.'\n",
        "\n",
        "# Set file parameters\n",
        "filename = 'classlist.xlsx'\n",
        "filepath = '/content/drive/MyDrive/attendance/' + filename\n",
        "\n",
        "# Create email message\n",
        "msg = MIMEMultipart()\n",
        "msg['From'] = sender\n",
        "msg['To'] = recipient\n",
        "msg['Subject'] = subject\n",
        "msg.attach(MIMEText(body))\n",
        "\n",
        "# Attach file to email message\n",
        "with open(filepath, \"rb\") as attachment:\n",
        "    part = MIMEBase(\"application\", \"octet-stream\")\n",
        "    part.set_payload(attachment.read())\n",
        "    encoders.encode_base64(part)\n",
        "    part.add_header(\"Content-Disposition\", f\"attachment; filename= {filename}\")\n",
        "    msg.attach(part)\n",
        "\n",
        "# Send email using SMTP server\n",
        "try:\n",
        "    server = smtplib.SMTP('smtp.gmail.com', 587)\n",
        "    server.starttls()\n",
        "    server.login(sender, password)\n",
        "    server.sendmail(sender, [recipient], msg.as_string())\n",
        "    server.quit()\n",
        "    print(f'Success: Email sent to {recipient} with attachment {filename}.')\n",
        "except Exception as e:\n",
        "    print(f'Error: Unable to send email to {recipient}.')\n",
        "    print(e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPVDX0Oah8tN",
        "outputId": "1b5de6cf-aff7-45d6-c9b3-c2b264c65655"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success: Email sent to aminysf23@gmail.com with attachment classlist.xlsx.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, render_template, request\n",
        "import google.auth\n",
        "from google.oauth2.credentials import Credentials\n",
        "from googleapiclient.discovery import build\n",
        "import pandas as pd\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Define the credentials required to access your Google Drive account\n",
        "creds = None\n",
        "if os.path.exists('token.json'):\n",
        "    creds = Credentials.from_authorized_user_file('token.json')"
      ],
      "metadata": {
        "id": "FXtF1KLey_hO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.oauth2.credentials import Credentials\n",
        "from google_auth_oauthlib.flow import InstalledAppFlow\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "# Set the scopes\n",
        "SCOPES = ['https://www.googleapis.com/auth/drive']\n",
        "\n",
        "# Set the path to your credentials file\n",
        "creds = Credentials.from_authorized_user_file('path/to/credentials.json', SCOPES)\n",
        "\n",
        "# If the credentials don't exist, run the authentication flow\n",
        "if not creds:\n",
        "    flow = InstalledAppFlow.from_client_secrets_file('path/to/client_secret.json', SCOPES)\n",
        "    creds = flow.run_local_server(port=0)\n",
        "\n",
        "# Build the Drive API client\n",
        "drive_service = build('drive', 'v3', credentials=creds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "ijpy5vkAzhva",
        "outputId": "f3a9384c-021b-4830-b1d6-f3b17a11a4c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-bc1e6b629612>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Set the path to your credentials file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mcreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCredentials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_authorized_user_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'path/to/credentials.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSCOPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# If the credentials don't exist, run the authentication flow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/oauth2/credentials.py\u001b[0m in \u001b[0;36mfrom_authorized_user_file\u001b[0;34m(cls, filename, scopes)\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mexpected\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \"\"\"\n\u001b[0;32m--> 438\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_authorized_user_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscopes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'path/to/credentials.json'"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}